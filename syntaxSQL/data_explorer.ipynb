{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import codecs\n",
    "import json\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain, count\n",
    "from six import string_types\n",
    "import torch\n",
    "import torchtext.data\n",
    "import torchtext.vocab\n",
    "\n",
    "import table\n",
    "import table.IO\n",
    "import opts\n",
    "from tree import SCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_WORD = '<unk>'\n",
    "UNK = 0\n",
    "PAD_WORD = '<blank>'\n",
    "PAD = 1\n",
    "BOS_WORD = '<s>'\n",
    "BOS = 2\n",
    "EOS_WORD = '</s>'\n",
    "EOS = 3\n",
    "SKP_WORD = '<sk>'\n",
    "SKP = 4\n",
    "RIG_WORD = '<]>'\n",
    "RIG = 5\n",
    "LFT_WORD = '<[>'\n",
    "LFT = 6\n",
    "special_token_list = [UNK_WORD, PAD_WORD, BOS_WORD, EOS_WORD, SKP_WORD, RIG_WORD, LFT_WORD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_index(tk_list):\n",
    "    stack = [0]\n",
    "    r_list = []\n",
    "    for i, tk in enumerate(tk_list):\n",
    "        r_list.append(stack[-1])\n",
    "        if tk.startswith('('):\n",
    "            # +1: because the parent of the top level is 0\n",
    "            stack.append(i+1)\n",
    "        elif tk ==')':\n",
    "            stack.pop()\n",
    "    # for EOS (</s>)\n",
    "    r_list.append(0)\n",
    "    return r_list\n",
    "\n",
    "\n",
    "def get_tgt_mask(lay_skip):\n",
    "    # 0: use layout encoding vectors; 1: use target word embeddings;\n",
    "    # with a <s> token at the first position\n",
    "    return [1] + [1 if tk in (SKP_WORD, RIG_WORD) else 0 for tk in lay_skip]\n",
    "\n",
    "\n",
    "def get_lay_index(lay_skip):\n",
    "    # with a <s> token at the first position\n",
    "    r_list = [0]\n",
    "    k = 0\n",
    "    for tk in lay_skip:\n",
    "        if tk in (SKP_WORD, RIG_WORD):\n",
    "            r_list.append(0)\n",
    "        else:\n",
    "            r_list.append(k)\n",
    "            k += 1\n",
    "    return r_list\n",
    "\n",
    "\n",
    "def get_tgt_loss(line, mask_target_loss):\n",
    "    r_list = []\n",
    "    for tk_tgt, tk_lay_skip in zip(line['tgt'], line['lay_skip']):\n",
    "        if tk_lay_skip in (SKP_WORD, RIG_WORD):\n",
    "            r_list.append(tk_tgt)\n",
    "        else:\n",
    "            if mask_target_loss:\n",
    "                r_list.append(PAD_WORD)\n",
    "            else:\n",
    "                r_list.append(tk_tgt)\n",
    "    return r_list\n",
    "\n",
    "\n",
    "def __getstate__(self):\n",
    "    return dict(self.__dict__, stoi=dict(self.stoi))\n",
    "\n",
    "\n",
    "def __setstate__(self, state):\n",
    "    self.__dict__.update(state)\n",
    "    self.stoi = defaultdict(lambda: 0, self.stoi)\n",
    "\n",
    "\n",
    "torchtext.vocab.Vocab.__getstate__ = __getstate__\n",
    "torchtext.vocab.Vocab.__setstate__ = __setstate__\n",
    "\n",
    "\n",
    "def filter_counter(freqs, min_freq):\n",
    "    cnt = Counter()\n",
    "    for k, v in freqs.items():\n",
    "        if (min_freq is None) or (v >= min_freq):\n",
    "            cnt[k] = v\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def merge_vocabs(vocabs, min_freq=0, vocab_size=None):\n",
    "    \"\"\"\n",
    "    Merge individual vocabularies (assumed to be generated from disjoint\n",
    "    documents) into a larger vocabulary.\n",
    "\n",
    "    Args:\n",
    "        vocabs: `torchtext.vocab.Vocab` vocabularies to be merged\n",
    "        vocab_size: `int` the final vocabulary size. `None` for no limit.\n",
    "    Return:\n",
    "        `torchtext.vocab.Vocab`\n",
    "    \"\"\"\n",
    "    merged = Counter()\n",
    "    for vocab in vocabs:\n",
    "        merged += filter_counter(vocab.freqs, min_freq)\n",
    "    return torchtext.vocab.Vocab(merged,\n",
    "                                 specials=list(special_token_list),\n",
    "                                 max_size=vocab_size, min_freq=min_freq)\n",
    "\n",
    "\n",
    "def join_dicts(*args):\n",
    "    \"\"\"\n",
    "    args: dictionaries with disjoint keys\n",
    "    returns: a single dictionary that has the union of these keys\n",
    "    \"\"\"\n",
    "    return dict(chain(*[d.items() for d in args]))\n",
    "\n",
    "def _preprocess_json(js):\n",
    "    t = SCode((js['token'], js['type']))\n",
    "    js['lay'] = t.layout(add_skip=False)\n",
    "    js['lay_skip'] = t.layout(add_skip=True)\n",
    "    assert len(t.target()) == len(js['lay_skip']), (list(zip(t.target(), js['lay_skip'])), ' '.join(js['tgt']))\n",
    "    js['tgt'] = t.target()\n",
    "\n",
    "def read_anno_json(anno_path):\n",
    "    with codecs.open(anno_path, \"r\", \"utf-8\") as corpus_file:\n",
    "        js_list = [json.loads(line) for line in corpus_file]\n",
    "        js_list = js_list[:5]\n",
    "        for js in js_list:\n",
    "            _preprocess_json(js)\n",
    "    return js_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "js_list = read_anno_json(test_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(js_list):\n",
    "    for js in js_list:\n",
    "        print(\"\\n\"+\"-\"*50)\n",
    "        for field in ['src', \"token\", \"type\", 'lay', \"lay_index\", \"lay_parent_index\",\\\n",
    "                      \"copy_to_tgt\", \"copy_to_ext\", \"tgt_mask\", \"tgt\", \"tgt_copy_ext\",\\\n",
    "                      \"tgt_parent_index\", \"tgt_loss\"]:\n",
    "            if field in ('src', 'lay', \"token\", \"type\"):\n",
    "                lines = js[field]\n",
    "            elif field in ('copy_to_tgt','copy_to_ext'):\n",
    "                lines = js['src']\n",
    "            elif field in ('tgt',):\n",
    "                def _tgt(line):\n",
    "                    r_list = []\n",
    "                    for tk_tgt, tk_lay_skip in zip(line['tgt'], line['lay_skip']):\n",
    "                        if tk_lay_skip in (SKP_WORD, RIG_WORD):\n",
    "                            r_list.append(tk_tgt)\n",
    "                        else:\n",
    "                            r_list.append(PAD_WORD)\n",
    "                    return r_list\n",
    "                lines = _tgt(js)\n",
    "            elif field in ('tgt_copy_ext',):\n",
    "                def _tgt_copy_ext(line):\n",
    "                    r_list = []\n",
    "                    src_set = set(line['src'])\n",
    "                    for tk_tgt in line['tgt']:\n",
    "                        if tk_tgt in src_set:\n",
    "                            r_list.append(tk_tgt)\n",
    "                        else:\n",
    "                            r_list.append(UNK_WORD)\n",
    "                    return r_list\n",
    "                lines = _tgt_copy_ext(js)\n",
    "            elif field in ('tgt_loss',):\n",
    "                lines = get_tgt_loss(js, False)\n",
    "            elif field in ('tgt_mask',):\n",
    "                lines = get_tgt_mask(js['lay_skip'])\n",
    "            elif field in ('lay_index',):\n",
    "                lines = get_lay_index(js['lay_skip'])\n",
    "            elif field in ('lay_parent_index',):\n",
    "                lines = get_parent_index(js['lay'])\n",
    "            elif field in ('tgt_parent_index',):\n",
    "                lines = get_parent_index(js['tgt'])\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            print(field + \": \", lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "src:  ['send', 'a', 'signal', '`', 'signal.SIGUSR1', '`', 'to', 'the', 'current', 'process']\n",
      "token:  ['os', '.', 'kill', '(', 'os', '.', 'getpid', '(', ')', ',', 'signal', '.', 'SIGUSR1', ')']\n",
      "type:  ['KEYWORD', 'OP', 'KEYWORD', 'OP', 'KEYWORD', 'OP', 'KEYWORD', 'OP', 'OP', 'OP', 'KEYWORD', 'OP', 'KEYWORD', 'OP']\n",
      "lay:  ['os', '.', 'kill', '(', 'os', '.', 'getpid', '(', ')', ',', 'signal', '.', 'SIGUSR1', ')']\n",
      "lay_index:  [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "lay_parent_index:  [0, 0, 0, 0, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 0]\n",
      "copy_to_tgt:  ['send', 'a', 'signal', '`', 'signal.SIGUSR1', '`', 'to', 'the', 'current', 'process']\n",
      "copy_to_ext:  ['send', 'a', 'signal', '`', 'signal.SIGUSR1', '`', 'to', 'the', 'current', 'process']\n",
      "tgt_mask:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tgt:  ['<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>']\n",
      "tgt_copy_ext:  ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'signal', '<unk>', '<unk>', '<unk>']\n",
      "tgt_parent_index:  [0, 0, 0, 0, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 0]\n",
      "tgt_loss:  ['os', '.', 'kill', '(', 'os', '.', 'getpid', '(', ')', ',', 'signal', '.', 'SIGUSR1', ')']\n",
      "\n",
      "--------------------------------------------------\n",
      "src:  ['decode', 'a', 'hex', 'string', \"'4a4b4c\", \"'\", 'to', 'UTF-8', '.']\n",
      "token:  ['bytes', '.', 'fromhex', '(', \"'4a4b4c'\", ')', '.', 'decode', '(', \"'utf-8'\", ')']\n",
      "type:  ['KEYWORD', 'OP', 'KEYWORD', 'OP', 'STRING', 'OP', 'OP', 'KEYWORD', 'OP', 'STRING', 'OP']\n",
      "lay:  ['bytes', '.', 'fromhex', '(', 'STRING', ')', '.', 'decode', '(', 'STRING', ')']\n",
      "lay_index:  [0, 0, 1, 2, 3, 4, 0, 5, 6, 7, 8, 9, 0, 10]\n",
      "lay_parent_index:  [0, 0, 0, 0, 4, 4, 0, 0, 0, 9, 9, 0]\n",
      "copy_to_tgt:  ['decode', 'a', 'hex', 'string', \"'4a4b4c\", \"'\", 'to', 'UTF-8', '.']\n",
      "copy_to_ext:  ['decode', 'a', 'hex', 'string', \"'4a4b4c\", \"'\", 'to', 'UTF-8', '.']\n",
      "tgt_mask:  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "tgt:  ['<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>']\n",
      "tgt_copy_ext:  ['<unk>', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'decode', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "tgt_parent_index:  [0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 10, 10, 10, 0]\n",
      "tgt_loss:  ['bytes', '.', 'fromhex', '(', '<[>', '<]>', ')', '.', 'decode', '(', '<[>', '<]>', ')']\n",
      "\n",
      "--------------------------------------------------\n",
      "src:  ['check', 'if', 'all', 'elements', 'in', 'list', '`', 'myList', '`', 'are', 'identical']\n",
      "token:  ['all', '(', 'x', '==', 'myList', '[', '0', ']', 'for', 'x', 'in', 'myList', ')']\n",
      "type:  ['KEYWORD', 'OP', 'NAME', 'OP', 'KEYWORD', 'OP', 'NUMBER', 'OP', 'KEYWORD', 'NAME', 'KEYWORD', 'KEYWORD', 'OP']\n",
      "lay:  ['all', '(', 'NAME', '==', 'myList', '[', 'NUMBER', ']', 'for', 'NAME', 'in', 'myList', ')']\n",
      "lay_index:  [0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "lay_parent_index:  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]\n",
      "copy_to_tgt:  ['check', 'if', 'all', 'elements', 'in', 'list', '`', 'myList', '`', 'are', 'identical']\n",
      "copy_to_ext:  ['check', 'if', 'all', 'elements', 'in', 'list', '`', 'myList', '`', 'are', 'identical']\n",
      "tgt_mask:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tgt:  ['<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>']\n",
      "tgt_copy_ext:  ['all', '<unk>', '<unk>', '<unk>', 'myList', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'in', 'myList', '<unk>']\n",
      "tgt_parent_index:  [0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]\n",
      "tgt_loss:  ['all', '(', 'x', '==', 'myList', '[', '0', ']', 'for', 'x', 'in', 'myList', ')']\n",
      "\n",
      "--------------------------------------------------\n",
      "src:  ['format', 'number', 'of', 'spaces', 'between', 'strings', '`', 'Python', '`', ',', '`', ':', '`', 'and', '`', 'Very', 'Good', '`', 'to', 'be', '`', '20', '`']\n",
      "token:  ['print', '(', \"'%*s#SPACE#:#SPACE#%*s'\", '%', '(', '20', ',', \"'Python'\", ',', '20', ',', \"'Very#SPACE#Good'\", ')', ')']\n",
      "type:  ['KEYWORD', 'OP', 'STRING', 'OP', 'OP', 'NUMBER', 'OP', 'STRING', 'OP', 'NUMBER', 'OP', 'STRING', 'OP', 'OP']\n",
      "lay:  ['print', '(', 'STRING', '%', '(', 'NUMBER', ',', 'STRING', ',', 'NUMBER', ',', 'STRING', ')', ')']\n",
      "lay_index:  [0, 0, 1, 2, 0, 3, 4, 5, 6, 7, 0, 8, 9, 10, 11, 0, 12, 13]\n",
      "lay_parent_index:  [0, 0, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 0]\n",
      "copy_to_tgt:  ['format', 'number', 'of', 'spaces', 'between', 'strings', '`', 'Python', '`', ',', '`', ':', '`', 'and', '`', 'Very', 'Good', '`', 'to', 'be', '`', '20', '`']\n",
      "copy_to_ext:  ['format', 'number', 'of', 'spaces', 'between', 'strings', '`', 'Python', '`', ',', '`', ':', '`', 'and', '`', 'Very', 'Good', '`', 'to', 'be', '`', '20', '`']\n",
      "tgt_mask:  [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "tgt:  ['<blank>', '<blank>', '<blank>', '<]>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>', '<blank>']\n",
      "tgt_copy_ext:  ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '20', ',', '<unk>', '<unk>', ',', '20', ',', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "tgt_parent_index:  [0, 0, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 0]\n",
      "tgt_loss:  ['print', '(', '<[>', '<]>', '%', '(', '20', ',', '<[>', '<]>', ',', '20', ',', '<[>', '<]>', ')', ')']\n",
      "\n",
      "--------------------------------------------------\n",
      "src:  ['How', 'to', 'convert', 'a', 'string', 'from', 'CP-1251', 'to', 'UTF-8', '?']\n",
      "token:  ['d', '.', 'decode', '(', \"'cp1251'\", ')', '.', 'encode', '(', \"'utf8'\", ')']\n",
      "type:  ['NAME', 'OP', 'KEYWORD', 'OP', 'STRING', 'OP', 'OP', 'KEYWORD', 'OP', 'STRING', 'OP']\n",
      "lay:  ['NAME', '.', 'decode', '(', 'STRING', ')', '.', 'encode', '(', 'STRING', ')']\n",
      "lay_index:  [0, 0, 1, 2, 3, 4, 0, 5, 6, 7, 8, 9, 0, 10]\n",
      "lay_parent_index:  [0, 0, 0, 0, 4, 4, 0, 0, 0, 9, 9, 0]\n",
      "copy_to_tgt:  ['How', 'to', 'convert', 'a', 'string', 'from', 'CP-1251', 'to', 'UTF-8', '?']\n",
      "copy_to_ext:  ['How', 'to', 'convert', 'a', 'string', 'from', 'CP-1251', 'to', 'UTF-8', '?']\n",
      "tgt_mask:  [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "tgt:  ['<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>', '<blank>', '<blank>', '<blank>', '<blank>', '<]>', '<blank>']\n",
      "tgt_copy_ext:  ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
      "tgt_parent_index:  [0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 10, 10, 10, 0]\n",
      "tgt_loss:  ['d', '.', 'decode', '(', '<[>', '<]>', ')', '.', 'encode', '(', '<[>', '<]>', ')']\n"
     ]
    }
   ],
   "source": [
    "process_data(js_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
